{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import lightgbm as lgbm\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "sink_list = []\n",
    "edges = {}\n",
    "with open(\"train.txt\", 'r') as f:\n",
    "    for data in f:\n",
    "        converted_data = data.split()\n",
    "        \n",
    "        for i in range(len(converted_data)-1):\n",
    "            result_list.append([converted_data[0], converted_data[i+1]])\n",
    "            edges[(converted_data[0], converted_data[i+1])] = 1\n",
    "tw_df = pd.DataFrame(result_list, columns=[\"Source\", \"Sink\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample = tw_df.sample(n = 200000)\n",
    "tw_df_temp = tw_df.drop(index = pos_sample.index.values)\n",
    "train_graph=nx.from_pandas_edgelist(tw_df_temp, \"Source\", \"Sink\", create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_edges = []\n",
    "while (len(missing_edges)<23946602):\n",
    "    if (len(missing_edges) >= 200000):\n",
    "        break\n",
    "    a=random.randint(1, 4867136)\n",
    "    b=random.randint(1, 4867136)\n",
    "    tmp = edges.get((a,b),-1)\n",
    "    if tmp == -1 and a!=b:\n",
    "       \n",
    "        try:\n",
    "            # adding points who less likely to be friends\n",
    "            if nx.shortest_path_length(whole_graph,source=a,target=b) > 2: \n",
    "\n",
    "                missing_edges.append([a,b])\n",
    "            else:\n",
    "                continue  \n",
    "        except:  \n",
    "             missing_edges.append([a,b])           \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df_neg = pd.DataFrame(missing_edges, columns=['Source', 'Sink'])\n",
    "neg_sample = tw_df_neg.sample(n = 200000)\n",
    "pos_sample[\"Linked\"] = np.ones(200000)\n",
    "neg_sample[\"Linked\"] = np.zeros(200000)\n",
    "all_sample = pos_sample.append(neg_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample = all_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_sample[[\"Source\", \"Sink\"]], all_sample[\"Linked\"], test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we start to generate some features for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_adar_in(a,b):\n",
    "    sum=0\n",
    "    try:\n",
    "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"num_followers_d\"] = \"\"\n",
    "X_train['num_followees_s'] = \"\"\n",
    "X_train['num_followees_d'] = \"\"\n",
    "X_train['inter_followers'] = \"\"\n",
    "X_train['inter_followees'] = \"\"\n",
    "X_test['num_followers_s'] = \"\"\n",
    "X_test['num_followers_d'] = \"\"\n",
    "X_test['num_followees_s'] = \"\"\n",
    "X_test['num_followees_d'] = \"\"\n",
    "X_test['inter_followers'] = \"\"\n",
    "X_test['inter_followees'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating no of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source and destination\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    for i,row in df_final.iterrows():\n",
    "        try:\n",
    "            s1=set(train_graph.predecessors(row['Source']))\n",
    "            s2=set(train_graph.successors(row['Source']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "        try:\n",
    "            d1=set(train_graph.predecessors(row['Sink']))\n",
    "            d2=set(train_graph.successors(row['Sink']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(s2))\n",
    "\n",
    "        num_followers_d.append(len(d1))\n",
    "        num_followees_d.append(len(d2))\n",
    "\n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "        inter_followees.append(len(s2.intersection(d2)))\n",
    "    \n",
    "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees\n",
    "X_train['num_followers_s'], X_train['num_followers_d'], X_train['num_followees_s'], X_train['num_followees_d'], X_train['inter_followers'], X_train['inter_followees']= compute_features_stage1(X_train)\n",
    "X_test['num_followers_s'], X_test['num_followers_d'], X_test['num_followees_s'], X_test['num_followees_d'], X_test['inter_followers'], X_test['inter_followees']= compute_features_stage1(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping adar index on train\n",
    "X_train['adar_index'] = X_train.apply(lambda row: calc_adar_in(row['Source'],row['Sink']),axis=1)\n",
    "#mapping adar index on test\n",
    "X_test['adar_index'] = X_test.apply(lambda row: calc_adar_in(row['Source'],row['Sink']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['Source', 'Sink'],axis=1,inplace=True)\n",
    "X_test.drop(['Source', 'Sink'],axis=1,inplace=True)\n",
    "d_train = lgbm.Dataset(X_train, label=y_train)\n",
    "\n",
    "d_test=lgbm.Dataset(X_test,label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also try a lightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 179853, number of negative: 180147\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5879\n",
      "[LightGBM] [Info] Number of data points in the train set: 360000, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499592 -> initscore=-0.001633\n",
      "[LightGBM] [Info] Start training from score -0.001633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's auc: 0.940016\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's auc: 0.940016\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's auc: 0.940016\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's auc: 1\n",
      "[5]\tvalid_0's auc: 1\n",
      "[6]\tvalid_0's auc: 1\n",
      "[7]\tvalid_0's auc: 1\n",
      "[8]\tvalid_0's auc: 1\n",
      "[9]\tvalid_0's auc: 1\n",
      "[10]\tvalid_0's auc: 1\n",
      "[11]\tvalid_0's auc: 1\n",
      "[12]\tvalid_0's auc: 1\n",
      "[13]\tvalid_0's auc: 1\n",
      "[14]\tvalid_0's auc: 1\n",
      "[15]\tvalid_0's auc: 1\n",
      "[16]\tvalid_0's auc: 1\n",
      "[17]\tvalid_0's auc: 1\n",
      "[18]\tvalid_0's auc: 1\n",
      "[19]\tvalid_0's auc: 1\n",
      "[20]\tvalid_0's auc: 1\n",
      "[21]\tvalid_0's auc: 1\n",
      "[22]\tvalid_0's auc: 1\n",
      "[23]\tvalid_0's auc: 1\n",
      "[24]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'num_threads' : 2,\n",
    "    'seed' : 76\n",
    "}\n",
    "\n",
    "parameters1 = {\n",
    "                'max_depth':10, # crtical parameter\n",
    "            'num_leaves': 800, # critical parameter, must be < 2^max_depth\n",
    "            'min_data_in_leaf': 3000, # critical parameter, avoid over-fitting\n",
    "    \n",
    "            'max_bin': 1000,  \n",
    "            'learning_rate': 0.1, # small rate with large iteration\n",
    "            'num_iterations': 1000,\n",
    "    \n",
    "            'objective': 'binary', # don't change\n",
    "            'feature_fraction': 0.9, # don't change, avoid over-fitting\n",
    "            'verbose': -1, # don't' change\n",
    "            'metric': 'auc', # don't change\n",
    "}\n",
    "\n",
    "clf_lightgbm = lgbm.train(parameters, d_train, valid_sets = d_test, num_boost_round=1000,\n",
    "                   early_stopping_rounds=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
