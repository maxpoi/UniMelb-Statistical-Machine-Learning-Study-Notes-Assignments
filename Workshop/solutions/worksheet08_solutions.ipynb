{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 8\n",
    "## Recurrent neural networks (RNNs)\n",
    "***\n",
    "\n",
    "In this worksheet, we'll implement a _recurrent neural network (RNN)_ for sentiment analysis of movie reviews. The input to the network will be a movie review, represented as a string, and the output will be a binary label which is \"1\" if the sentiment is _positive_ and \"0\" if the sentiment is _negative_. In practice, a network like this could be applied to social media monitoring—e.g. tracking customer's perceptions of a new product, or prioritising support for disgruntled customers.\n",
    "\n",
    "By the end of this worksheet, you should be able to:\n",
    "\n",
    "* convert raw text to a vector representation for input into a neural network\n",
    "* build a neural network with a recurrent architecture to take advantage of the _order_ of words in text\n",
    "* use `tf.data` to feed data into neural network as an alternative to NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 108\n",
    "\n",
    "import tensorflow as tf\n",
    "from packaging import version\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.3\"), \\\n",
    "    \"This notebook requires TensorFlow 2.3 or above.\"\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Large Movie Review (IMDb) Dataset\n",
    "\n",
    "In order to train and evaluate our sentiment analysis model, we'll use the _Large Movie Review Dataset_. \n",
    "It contains 50,000 movie reviews crawled from the [IMDb website](https://www.imdb.com/), split evenly into train/test sets.\n",
    "The dataset excludes _neutral reviews_ (with a rating $> 4/10$ and $< 7/10$) and defines:\n",
    "\n",
    "* a _positive review_ as having a rating $\\geq 7/10$ \n",
    "* a _negative review_ as having a rating $\\leq 4/10$.\n",
    "\n",
    "More information about the dataset is available [here](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
    "\n",
    "We'll download the dataset using the [TensorFlow Datasets (TFDS) library](https://www.tensorflow.org/datasets/overview), which provides access to a variety of machine learning datasets.\n",
    "First, we need to install the TFDS library using `pip`, since it's not included in core TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing the library, we can use it to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "(train_ds, test_ds), ds_info = tfds.load(name='imdb_reviews', split=('train', 'test'), as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train_ds` and `test_ds` variables represent the train/test datasets respectively, however **they aren't stored in NumPy arrays as we're used to**.\n",
    "Instead, the TFDS library returns a special type of object called a [TensorFlow Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\n",
    "A `Dataset` offers two main advantages over NumPy arrays:\n",
    "\n",
    "1. It can represent large datasets _without reading all of the data into memory_. This is important for large-scale applications, where the dataset must be streamed from disk into memory.\n",
    "2. It represents the output of a _data pipeline_ (which may include transformations) rather than the data itself.\n",
    "\n",
    "Since a `Dataset` is not guaranteed to completely exist in memory, random access (i.e. indexing) is not supported.\n",
    "Instead, a `Dataset` behaves more like a Python iterable—we can only request the _next_ element, which may be a single instance or a batch of instances.\n",
    "\n",
    "Let's iterate over the first 3 elements in `train_ds` and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A negative review:\n",
      " This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it. \n",
      "\n",
      "A negative review:\n",
      " I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all. \n",
      "\n",
      "A negative review:\n",
      " Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(3).as_numpy_iterator():\n",
    "    # decode binary string to UTF-8\n",
    "    review = x.decode()\n",
    "    # convert integer binary label to string\n",
    "    label = \"positive\" if y == 1 else \"negative\"\n",
    "    print(\"A {} review:\\n\".format(label), review, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** Based on the above training examples, what features do you think will be important for predicting positive/negative sentiment? If the words in the text were randomly shuffled, do you think accuracy would suffer?\n",
    "\n",
    "_Answer:_ The word order is probably not crucial for predicting sentiment. The absence or presence of certain words provide a strong signal, regardless of where they appear in the text. For example, the presence of words like \"terrible\", \"disappointed\" and \"ridiculous\" are likely to be correlated with negative sentiment. However, mistakes could be made if word order is ignored—e.g. \"terrible\" may refer to an experience a character goes through in a movie, rather than the movie itself.\n",
    "***\n",
    "\n",
    "When working with Datasets, batching and random shuffling are treated as steps in the data input pipeline.\n",
    "In the code block below, we add these steps to the pipeline in preparation for pre-processing and training:\n",
    "\n",
    "* First, we cache the entire dataset in memory. This is okay since the dataset is relatively small.\n",
    "* Second, we randomly shuffle the instances.\n",
    "* Third, we group the instances into batches of size 128.\n",
    "* Fourth, we call prefetch to reduce latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache()\n",
    "train_ds = train_ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "train_ds = train_ds.batch(128)\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_ds = test_ds.cache()\n",
    "test_ds = test_ds.shuffle(ds_info.splits['test'].num_examples)\n",
    "test_ds = test_ds.batch(128)\n",
    "test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text preprocessing\n",
    "\n",
    "In order to feed textual data into a neural network, we need to transform it into a vector representation.\n",
    "This is often done in two steps:\n",
    "\n",
    "1. **Tokenisation.**\n",
    "The text is split into a sequence of words/tokens. \n",
    "For example, when splitting on white space, the text \"This was an absolutely terrible movie\" would become \\[\"This\", \"was\", \"an\", \"absolutely\", \"terrible\", \"movie\"\\].\n",
    "\n",
    "2. **Word vectorisation/embedding.** \n",
    "Individual words/tokens are mapped to a vector representation. \n",
    "We'll start with a simple one-hot vector encoding, and map to a lower-dimensional representation later on.\n",
    "\n",
    "For the one-hot vector encoding, we choose a vocabulary of size $K$.\n",
    "Each word in the vocabulary is associated with a dimension in the space, or equivalently a word id in the set $\\{0, \\ldots, K-1\\}$.\n",
    "Word ids 0 and 1 are reserved to represent _padding_ and _unknown words_ (also known as out-of-vocabulary words), respectively.\n",
    "\n",
    "In between steps 1 and 2 above, we'll also do some **standardisation**:\n",
    "\n",
    "* we'll convert text to lowercase\n",
    "* we'll remove HTML break tags \"\\<br /\\>\" (which you might have noticed in the third review we printed out above)\n",
    "* we'll remove punctuation characters\n",
    "\n",
    "We can perform all of these steps using a built-in layer from Keras called [`TextVectorization`](https://keras.io/api/layers/preprocessing_layers/core_preprocessing_layers/text_vectorization/).\n",
    "It does everything we need by default, apart from the standardisation, which we need to specify manually.\n",
    "\n",
    "In the code block below, we define a function to perform standardisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def custom_standardisation(input_data):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_data : a Tensor of shape (batch_size,)\n",
    "    \n",
    "    Return:\n",
    "        a Tensor of shape (batch_size,)\n",
    "    \"\"\"\n",
    "    # Convert string to lowercase\n",
    "    input_data = tf.strings.lower(input_data)\n",
    "    \n",
    "    # Remove break tags\n",
    "    input_data = tf.strings.regex_replace(input_data, \"<br />\", \" \")\n",
    "    \n",
    "    # Remove punctuation\n",
    "    punctuation_pattern = \"[%s]\" % re.escape(string.punctuation)\n",
    "    input_data = tf.strings.regex_replace(input_data, punctuation_pattern, \"\")\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the `TextVectorization` layer. \n",
    "Note that we're limiting the size of the vocabulary to $K = 5000$. \n",
    "We'll also require that the sequences be of uniform length 300 to improve efficiency.\n",
    "If a review contains more than 300 words, only the first 300 words will be kept.\n",
    "If a review contains less than 300 words, the remaining \"slots\" will be filled with padding (id 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "MAX_LEN = 300\n",
    "vectorise_layer = TextVectorization(max_tokens=VOCAB_SIZE, output_mode=\"int\", \n",
    "                                    standardize=custom_standardisation, \n",
    "                                    output_sequence_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the vocabulary for the layer, we need to call the `adapt` method and pass in some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset without class labels\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorise_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the learned vocabulary using the `get_vocabulary` method. \n",
    "The most frequently occurring words are assigned the smallest integer ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorise_layer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our `TextVectorization` layer, let's apply it to the first batch of training data and print out the first 3 examples in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 235   28    5    2 2523 2627    5 1020    4 2505  910  379    8   11\n",
      "   411    2  882 2952    5 2529   16    4    1 1550    1  550    7    2\n",
      "    85  277  568   20    1    5    2  332 2072  857    6 2193    4   50\n",
      "   433  409    5  967    3  131    2 2011  207  176  202  241    8   11\n",
      "  3178    2  277 3758    7 1083   16    1    8  783  288    2  909  208\n",
      "   179  821   14  205   14    2  508    7 1619    6 1679   15   30    2\n",
      "     1    1   35    2  262 2884    2 4090  207   20   99 2151 1935    8\n",
      "    11  379  297 4026   43  249    4  393 1172   15   24 1032    6 1100\n",
      "    46   59  127 4406    4   73 1849  999  100  291 1815    5    1  158\n",
      "     2    1 1172    4    1  186    7   52 2235   18    9   61  296    4\n",
      "   163  225  154  138  897  555  881    1  500  252    1    5    4  446\n",
      "  4944   12  180    6  208  785   45    5 2351    1  158  513   80   81\n",
      "   876    1  714  178    4  247  885    4 1658    1  108    1   43    4\n",
      "     1   16    4 3659    3 4026 1530    4 1661 2723   16    2  490    8\n",
      "     2 3099    5  212  115    3    2  230   36  335    6 1276   20   87\n",
      "    31    2 1741 1390    8    4    1    1 4937    3   29  765    6   67\n",
      "   134 4026    3    1   23 2909    6  806   45  704  165   20  154 1753\n",
      "   203 1443    2  313    7    4  345   28    1  266  493   45    6   26\n",
      "   233   35    1    2  642 1936  188   20    2 2967    7  239 1084 1131\n",
      "     9   15    4  458  466    5  671   12  144  856   73   16    2  346\n",
      "     5  257  276  485   45  468  171  208    2  126    3    2    1  793\n",
      "     1    6  119    4 2762  507]\n",
      " [  10  209   11   17   20  244   11 2659    3   10  175   67   86  250\n",
      "    68  856  140   11  409    5 1180   29   21  160   31   30    3    9\n",
      "   296  123    1  185    4  163    1   10  118   11   17    7   15  324\n",
      "    18   12  144  378    2  857  139  188   64 1610   15 2428   10 2070\n",
      "    12  857   65 1218  184    4 1039 1589 2712    3 2549   12    4    2\n",
      "   694    1    1  194  471  951    4  700 2143 3685  551   68    1   20\n",
      "     4  756 2143 3685 4744    1 1919  324  139  204  539    1 4517   16\n",
      "  1812   83    2    1   76  777   15  226    3 2162  443 1815    5    1\n",
      "  2259    7   30   22  349    6 1563   56 2861    1   16    1   28   49\n",
      "   150   10   68  130   42   11   17    7    9 1313    2 4217    1 1376\n",
      "     8    2  183   12  408 2294 1753  275    2  457   31 3246   97  350\n",
      "    11   17   15    4   49  471   89 1359   16   11    1 1286   15    4\n",
      "    17    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [  11  119   13    4    1    8  314  218   14    9   13    2   85 2713\n",
      "     6  332   33   30    1  173 1017  148    9   13  109    1   20  687\n",
      "   244    2    1  220   23    4  330    1  220  570    8    4    1 3915\n",
      "     2 1229    7  487  571   27  486    6  532    2  311   18   24  317\n",
      "  4124  204  203    2  122    5   87    2  291  465   23    2 1564    1\n",
      "     2 4301    1    3    2  181 2841  517  489  204  584   77    2  311\n",
      "     7    1    1  462    1   10  285  104  642    5   11  119   20    1\n",
      "   325 1817    3  389    3    2    1  220    2   61  104   20    2 2114\n",
      "    22  193   26  526  134   43   33  646  508  285    4  200   12   43\n",
      "   109   74  597   41  952  542    5    8   24  698    2 1470    7   11\n",
      "     8    1    1   85   30  325 2713  367   45  487    2    1   61  104\n",
      "   200   65   90    3    9  149  180 1555   18   10  285   33  379    3\n",
      "    13   62 1501   91   10    1   12    2 2877   65    1    6   49  206\n",
      "    34   65  596    2  166  101   18   16  265 1396 1250 2843   13    2\n",
      "  1229   24  317   13 4672 2843    3    2  291  465   65    1    4  181\n",
      "     1 1413 4322    3    1    1    1  462   13    1    6  320   42    2\n",
      "     1   10   25 1051    4  716   42   12 1799  145   49  206   61  104\n",
      "   178 3181   69   85  127   13    2  626  751 3194  374    3 4074   13\n",
      "     2  305 2085   10   38  305 2085   18    8   11 1791   58  130    4\n",
      "  1049  160  360    3    2  305   58  137 1166    3  365    1  946   35\n",
      "    12    9   13    4   52  160  119  601  431   50  642  466   56   20\n",
      "     1    3  601  431   12  284]]\n"
     ]
    }
   ],
   "source": [
    "for batch in text_ds.take(1).map(vectorise_layer).as_numpy_iterator():\n",
    "    print(batch[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RNN-based classifier\n",
    "\n",
    "Now that we've prepared a layer for preprocessing, we're ready to implement the neural network.\n",
    "The network will consist of three main components:\n",
    "\n",
    "1. **Embedding layer.** This layer will map word vectors from a sparse one-hot encoded representation to a dense lower-dimensional embedding space. It is effectively equivalent to a dense layer with a linear activation function.\n",
    "2. **RNN layer.** This layer will sequentially apply an RNN cell to the densely-encoded word vectors. Since we're doing classification, we only need to use the output at the _end of the sequence_. In other applications, such as language modelling, we would use the output from _each element of the sequence_.\n",
    "3. **Dense layers.** These layers will process the final output of the RNN layer to produce a sentiment classification.\n",
    "\n",
    "***\n",
    "**Exercise:** Complete the following code block to implement an RNN-based sentiment classifier. You should add three layers: \n",
    "\n",
    "* an `LSTM` layer with `L_UNITS = 32` units followed by \n",
    "* a `Dense` layer with `D1_UNITS = 32` units, and \n",
    "* a `Dense` layer with 1 unit. \n",
    "\n",
    "\\[Note: you may like to experiment with your own architecture. For example, you could use an `SimpleRNN` layer in place of a `LSTM` layer, or a `Bidirectional` RNN.\\]\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 169,409\n",
      "Trainable params: 169,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DIM_EMBED = 32\n",
    "L_UNITS = 32\n",
    "D1_UNITS = 32\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Specify that the model will accept a 1D tensor of strings as input with \n",
    "    # an unknown batch size\n",
    "    keras.Input(shape=(None,), dtype=tf.string),\n",
    "    \n",
    "    # Vectorise the strings using the preprocessing layer we defined above\n",
    "    vectorise_layer,\n",
    "    \n",
    "    # Map the sequence of one-hot encoded integer vectors to a \n",
    "    # lower-dimensional embedding space. By setting `mask_zero = True`, we \n",
    "    # instruct Keras to apply a mask so that downstream layers can ignore \n",
    "    # padded parts of the sequence.\n",
    "    layers.Embedding(VOCAB_SIZE, DIM_EMBED, mask_zero=True),\n",
    "    \n",
    "    # Sequentially apply an LSTM cell to the sequence of word embeddings, \n",
    "    # returning only the final output\n",
    "    layers.LSTM(L_UNITS), # fill in\n",
    "    \n",
    "    # Apply two dense layers to output the probability of a positive sentiment\n",
    "    layers.Dense(D1_UNITS, activation='relu'), # fill in\n",
    "    layers.Dense(1, activation='sigmoid') # fill in\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the final output is a scalar corresponding to the probability of a positive sentiment, we'll minimise the binary cross-entropy loss.\n",
    "\n",
    "In the code block below, we compile the model and run training for 15 epochs.\n",
    "Training may take 10-15 min to complete on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "196/196 [==============================] - 62s 315ms/step - loss: 0.6927 - accuracy: 0.5167 - val_loss: 0.6917 - val_accuracy: 0.5405\n",
      "Epoch 2/15\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 0.6422 - accuracy: 0.6617 - val_loss: 0.5596 - val_accuracy: 0.7965\n",
      "Epoch 3/15\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 0.4864 - accuracy: 0.8267 - val_loss: 0.4411 - val_accuracy: 0.8257\n",
      "Epoch 4/15\n",
      "196/196 [==============================] - 65s 330ms/step - loss: 0.3633 - accuracy: 0.8618 - val_loss: 0.3513 - val_accuracy: 0.8576\n",
      "Epoch 5/15\n",
      "196/196 [==============================] - 64s 325ms/step - loss: 0.2918 - accuracy: 0.8894 - val_loss: 0.3269 - val_accuracy: 0.8656\n",
      "Epoch 6/15\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 0.2592 - accuracy: 0.9042 - val_loss: 0.3165 - val_accuracy: 0.8694\n",
      "Epoch 7/15\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 0.2365 - accuracy: 0.9136 - val_loss: 0.3265 - val_accuracy: 0.8692\n",
      "Epoch 8/15\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.2219 - accuracy: 0.9210 - val_loss: 0.3163 - val_accuracy: 0.8699\n",
      "Epoch 9/15\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 0.2093 - accuracy: 0.9276 - val_loss: 0.3407 - val_accuracy: 0.8661\n",
      "Epoch 10/15\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 0.1993 - accuracy: 0.9314 - val_loss: 0.3320 - val_accuracy: 0.8672\n",
      "Epoch 11/15\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 0.1874 - accuracy: 0.9382 - val_loss: 0.3466 - val_accuracy: 0.8649\n",
      "Epoch 12/15\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 0.1802 - accuracy: 0.9406 - val_loss: 0.3402 - val_accuracy: 0.8642\n",
      "Epoch 13/15\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 0.1739 - accuracy: 0.9444 - val_loss: 0.3584 - val_accuracy: 0.8609\n",
      "Epoch 14/15\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 0.1671 - accuracy: 0.9481 - val_loss: 0.3765 - val_accuracy: 0.8602\n",
      "Epoch 15/15\n",
      "196/196 [==============================] - 56s 283ms/step - loss: 0.1647 - accuracy: 0.9480 - val_loss: 0.3695 - val_accuracy: 0.8589\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot loss curves to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], label='Train')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='Test')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss curves show that the model is overfitting, as the training loss has dropped below the test loss.\n",
    "\n",
    "***\n",
    "**Question:** What actions can we take to prevent overfitting? What could be the main cause of overfitting in this case?\n",
    "\n",
    "_Answer:_ \n",
    "It's not surprising that the model is overfitting, as the training data is relatively small, and we have not applied any regularisation.\n",
    "Looking at the number of parameters in the various layers, we see that the `Embedding` layer contains 94\\% of the total parameters. \n",
    "So it may be one of the main culprits for overfitting.\n",
    "\n",
    "To reduce overfitting of the embedding layer in particular, we could try:\n",
    "\n",
    "* Reducing the size of the vocabulary and/or embedding space.\n",
    "* Applying dropout to the features in the embedding space. This can be done by adding a `Dropout` layer after the `Embedding` layer.\n",
    "* Using a pre-trained embedding layer. [TensorFlow Hub](https://tfhub.dev/) provides a repository of pretrained models/layers. For example, we could use the [gnews-swivel-20dim](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1) word embedding which was trained on a 130GB corpus of English news articles.\n",
    "* Using more movie review data (if we can find some).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing the model\n",
    "\n",
    "Since we integrated text prepocessing into the model, it's straightforward to apply it to new test instances. \n",
    "We can simply pass in a NumPy array of strings, and immediately get sentiment predictions.\n",
    "\n",
    "***\n",
    "**Exercise:** Test the sentiment classification model on a movie review of your own.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My review:\n",
      " The plot is nothing, the narrative arc is all over the place, and the comedy is tired and sad.\n",
      "Sentiment:  0.22416309\n"
     ]
    }
   ],
   "source": [
    "# fill in\n",
    "my_review = \"The plot is nothing, the narrative arc is all over the place, and the comedy is tired and sad.\"\n",
    "print(\"My review:\\n\", my_review)\n",
    "\n",
    "pred_sentiment = model.predict(np.expand_dims(my_review, 0))\n",
    "print(\"Sentiment: \", pred_sentiment.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: visualising the embedding space (optional)\n",
    "\n",
    "***\n",
    "**Exercise:** Run the code block below to save the word dictionary and weights in the `Embedding` layer as TSV files. You can then load these files in the [Embedding Projector](http://projector.tensorflow.org/) web app to visualise the embedding space.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "tokens = model.layers[0].get_weights()[0]\n",
    "ids = model.layers[0].get_weights()[1]\n",
    "tokens = tokens[np.argsort(ids)]\n",
    "ids = ids[np.argsort(ids)]\n",
    "embedding_weights = model.layers[1].get_weights()[0]\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for idx, token in zip(ids[2::], tokens[2::]):\n",
    "    vec = embedding_weights[idx]\n",
    "    out_m.write(token.decode() + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
